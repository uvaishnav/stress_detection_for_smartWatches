{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')  # Add source directory to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal_processing.base_signal_processor import BaseSignalProcessor\n",
    "from signal_processing.motion_artifact_detector import MotionArtifactDetector\n",
    "from signal_processing.adaptive_filter import AdaptiveFilter\n",
    "from signal_processing.kalman_filter import KalmanFilter\n",
    "from signal_processing.wavelet_denoiser import WaveletDenoiser\n",
    "from signal_processing.pipeline import SignalProcessingPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Unified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading unified dataset...\n",
      "                                 bvp  label  subject_id    dataset  \\\n",
      "2020-01-03 08:00:00+00:00   5.673109      0           2  physionet   \n",
      "2020-01-03 08:00:00+00:00   7.687833      0           2  physionet   \n",
      "2020-01-03 08:00:00+00:00   1.509560      0           2  physionet   \n",
      "2020-01-03 08:00:00+00:00  12.999866      0           2  physionet   \n",
      "2020-01-03 08:00:00+00:00  20.798602      0           2  physionet   \n",
      "\n",
      "                                 device skin_tone  noise_level     acc_x  \\\n",
      "2020-01-03 08:00:00+00:00   apple_watch      V-VI      0.05088 -0.817685   \n",
      "2020-01-03 08:00:00+00:00   apple_watch      I-II      0.07712 -0.973498   \n",
      "2020-01-03 08:00:00+00:00   apple_watch    III-IV      0.06400 -1.054134   \n",
      "2020-01-03 08:00:00+00:00  galaxy_watch    III-IV      0.09600 -1.000000   \n",
      "2020-01-03 08:00:00+00:00  galaxy_watch      V-VI      0.07632 -1.000000   \n",
      "\n",
      "                               acc_y     acc_z  \n",
      "2020-01-03 08:00:00+00:00 -62.628226  4.996602  \n",
      "2020-01-03 08:00:00+00:00 -62.739436  5.184150  \n",
      "2020-01-03 08:00:00+00:00 -62.992483  5.020381  \n",
      "2020-01-03 08:00:00+00:00 -69.300000  5.000000  \n",
      "2020-01-03 08:00:00+00:00 -69.300000  5.000000  \n"
     ]
    }
   ],
   "source": [
    "processor = BaseSignalProcessor(data_path=\"../data/processed/cleaned_unified_dataset.parquet\")\n",
    "dataset = processor.load_data()\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _robust_normalize(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Enhanced normalization with fallback\"\"\"\n",
    "    data = np.nan_to_num(data, nan=np.median(data))\n",
    "        \n",
    "    # Fallback to std if IQR is zero\n",
    "    q75, q25 = np.percentile(data, [75, 25])\n",
    "    iqr = q75 - q25\n",
    "    if iqr < 1e-6:\n",
    "        std = np.std(data) + 1e-6\n",
    "        normalized = (data - np.mean(data)) / std\n",
    "    else:\n",
    "        normalized = (data - np.median(data)) / iqr\n",
    "        \n",
    "    # Secondary clipping\n",
    "    return np.clip(normalized, -3, 3)\n",
    "\n",
    "# Compute and normalize accelerometer magnitude\n",
    "dataset['acc_mag'] = np.sqrt(dataset['acc_x']**2 + dataset['acc_y']**2 + dataset['acc_z']**2)\n",
    "dataset['acc_mag'] = _robust_normalize(dataset['acc_mag'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Artifact Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              acc_x      acc_y     acc_z  motion_burst\n",
      "2020-01-03 08:00:00+00:00 -0.817685 -62.628226  4.996602           0.0\n",
      "2020-01-03 08:00:00+00:00 -0.973498 -62.739436  5.184150           0.0\n",
      "2020-01-03 08:00:00+00:00 -1.054134 -62.992483  5.020381           0.0\n",
      "2020-01-03 08:00:00+00:00 -1.000000 -69.300000  5.000000           0.0\n",
      "2020-01-03 08:00:00+00:00 -1.000000 -69.300000  5.000000           0.0\n"
     ]
    }
   ],
   "source": [
    "detector = MotionArtifactDetector()\n",
    "dataset = detector.detect_motion_bursts(dataset)\n",
    "print(dataset[['acc_x', 'acc_y', 'acc_z', 'motion_burst']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts of motion_burst:\n",
      "motion_burst\n",
      "0.0    6397175\n",
      "1.0     157578\n",
      "Name: count, dtype: int64\n",
      "Motion Burst Distribution:\n",
      "motion_burst\n",
      "0.0    97.595973\n",
      "1.0     2.404027\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "num_unique_motion_bursts = dataset['motion_burst'].nunique()\n",
    "motion_burst_counts = dataset['motion_burst'].value_counts()\n",
    "print(f\"Value counts of motion_burst:\\n{motion_burst_counts}\")\n",
    "\n",
    "# Check motion burst distribution\n",
    "motion_burst_counts = dataset['motion_burst'].value_counts(normalize=True) * 100\n",
    "print(f\"Motion Burst Distribution:\\n{motion_burst_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New artifact density: 2.40%\n",
      "count    6.554753e+06\n",
      "mean     4.667615e-01\n",
      "std      9.818329e-01\n",
      "min     -8.811038e-01\n",
      "25%     -4.866879e-02\n",
      "50%      0.000000e+00\n",
      "75%      9.513312e-01\n",
      "max      1.122975e+01\n",
      "Name: acc_mag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"New artifact density: {dataset['motion_burst'].mean() * 100:.2f}%\")\n",
    "print(dataset['acc_mag'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Visualize results\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(dataset['acc_mag'], label=\"Accelerometer Magnitude\")\n",
    "# plt.plot(dataset['motion_burst'] * dataset['acc_mag'].max(), label=\"Motion Bursts\", linestyle='--')\n",
    "# plt.legend()\n",
    "# plt.title(\"Motion Burst Detection\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Filtering for Motion Artifact Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_filter = AdaptiveFilter()\n",
    "cleaned_bvp = adaptive_filter.apply_adaptive_filter(\n",
    "    noisy_signal=dataset['bvp'].values,\n",
    "    reference_signal=dataset['acc_mag'].values,\n",
    "    motion_burst=dataset['motion_burst'].values\n",
    ")\n",
    "dataset['bvp_cleaned'] = cleaned_bvp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kalman_filter = KalmanFilter()\n",
    "bvp_smoothed = kalman_filter.apply_kalman_filter(\n",
    "    signal=dataset['bvp_cleaned'].values,\n",
    "    motion_burst=dataset['motion_burst'].values\n",
    ")\n",
    "dataset['bvp_smoothed'] = bvp_smoothed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "wavelet_denoiser = WaveletDenoiser()\n",
    "\n",
    "denoised_bvp = wavelet_denoiser.apply_wavelet_denoising(\n",
    "    dataset['bvp_smoothed'].values,\n",
    "    motion_burst=dataset['motion_burst'].values,\n",
    "    skin_tone=dataset['skin_tone'].iloc[0],\n",
    "    noise_level=dataset['noise_level'].median()  # Add noise level from dataset\n",
    ")\n",
    "\n",
    "# Verify lengths match before assignment\n",
    "assert len(denoised_bvp) == len(dataset), \"Denoised signal length mismatch\"\n",
    "\n",
    "dataset['bvp_denoised'] = denoised_bvp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnig the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:First chunk rejected, using raw signal with noise reduction\n"
     ]
    }
   ],
   "source": [
    "dataset_ = pd.read_parquet(\"../data/processed/cleaned_unified_dataset.parquet\")\n",
    "pipeline = SignalProcessingPipeline()\n",
    "processed_df = pipeline.process_signal(dataset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bvp</th>\n",
       "      <th>bvp_cleaned</th>\n",
       "      <th>bvp_smoothed</th>\n",
       "      <th>bvp_denoised</th>\n",
       "      <th>motion_burst</th>\n",
       "      <th>acc_mag</th>\n",
       "      <th>device</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>noise_level</th>\n",
       "      <th>label</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-03 08:00:00+00:00</th>\n",
       "      <td>5.673109</td>\n",
       "      <td>5.559646</td>\n",
       "      <td>3.808351</td>\n",
       "      <td>3.900794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023022</td>\n",
       "      <td>apple_watch</td>\n",
       "      <td>V-VI</td>\n",
       "      <td>0.05088</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 08:00:00+00:00</th>\n",
       "      <td>7.687833</td>\n",
       "      <td>7.534076</td>\n",
       "      <td>4.133103</td>\n",
       "      <td>4.185340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.021271</td>\n",
       "      <td>apple_watch</td>\n",
       "      <td>I-II</td>\n",
       "      <td>0.07712</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 08:00:00+00:00</th>\n",
       "      <td>1.509560</td>\n",
       "      <td>1.479369</td>\n",
       "      <td>4.258502</td>\n",
       "      <td>4.282481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.017990</td>\n",
       "      <td>apple_watch</td>\n",
       "      <td>III-IV</td>\n",
       "      <td>0.06400</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 08:00:00+00:00</th>\n",
       "      <td>12.999866</td>\n",
       "      <td>12.739869</td>\n",
       "      <td>4.326370</td>\n",
       "      <td>4.328632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.016824</td>\n",
       "      <td>galaxy_watch</td>\n",
       "      <td>III-IV</td>\n",
       "      <td>0.09600</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03 08:00:00+00:00</th>\n",
       "      <td>20.798602</td>\n",
       "      <td>20.382630</td>\n",
       "      <td>4.369558</td>\n",
       "      <td>4.357221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.016824</td>\n",
       "      <td>galaxy_watch</td>\n",
       "      <td>V-VI</td>\n",
       "      <td>0.07632</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 bvp  bvp_cleaned  bvp_smoothed  bvp_denoised  \\\n",
       "2020-01-03 08:00:00+00:00   5.673109     5.559646      3.808351      3.900794   \n",
       "2020-01-03 08:00:00+00:00   7.687833     7.534076      4.133103      4.185340   \n",
       "2020-01-03 08:00:00+00:00   1.509560     1.479369      4.258502      4.282481   \n",
       "2020-01-03 08:00:00+00:00  12.999866    12.739869      4.326370      4.328632   \n",
       "2020-01-03 08:00:00+00:00  20.798602    20.382630      4.369558      4.357221   \n",
       "\n",
       "                           motion_burst   acc_mag        device skin_tone  \\\n",
       "2020-01-03 08:00:00+00:00           0.0 -0.023022   apple_watch      V-VI   \n",
       "2020-01-03 08:00:00+00:00           0.0 -0.021271   apple_watch      I-II   \n",
       "2020-01-03 08:00:00+00:00           0.0 -0.017990   apple_watch    III-IV   \n",
       "2020-01-03 08:00:00+00:00           0.0  1.016824  galaxy_watch    III-IV   \n",
       "2020-01-03 08:00:00+00:00           0.0  1.016824  galaxy_watch      V-VI   \n",
       "\n",
       "                           noise_level  label  subject_id  \n",
       "2020-01-03 08:00:00+00:00      0.05088      0           2  \n",
       "2020-01-03 08:00:00+00:00      0.07712      0           2  \n",
       "2020-01-03 08:00:00+00:00      0.06400      0           2  \n",
       "2020-01-03 08:00:00+00:00      0.09600      0           2  \n",
       "2020-01-03 08:00:00+00:00      0.07632      0           2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bvp             28.719013\n",
      "bvp_cleaned      2.112163\n",
      "bvp_smoothed     1.719293\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(processed_df[['bvp', 'bvp_cleaned', 'bvp_smoothed']].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import correlate\n",
    "from scipy.signal import periodogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Quality Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalQualityMetrics:\n",
    "    def compute_snr(self, cleaned: np.ndarray, original: np.ndarray, \n",
    "                   noise_level: np.ndarray = None, fs: int = 30) -> float:\n",
    "        \"\"\"\n",
    "        Compute noise-aware SNR with spectral weighting.\n",
    "        \n",
    "        Parameters:\n",
    "            cleaned (np.ndarray): Processed signal\n",
    "            original (np.ndarray): Original noisy signal\n",
    "            noise_level (np.ndarray): Array of noise levels from dataset\n",
    "            fs (int): Sampling frequency\n",
    "            \n",
    "        Returns:\n",
    "            float: SNR in dB\n",
    "        \"\"\"\n",
    "        # 1. Spectral alignment\n",
    "        freqs, psd_clean = periodogram(cleaned, fs=fs)\n",
    "        _, psd_noisy = periodogram(original, fs=fs)\n",
    "        \n",
    "        # 2. Noise-floor estimation using dataset's noise level\n",
    "        if noise_level is not None:\n",
    "            # Resample noise level to match PSD bins\n",
    "            noise_weights = np.interp(freqs, \n",
    "                                    np.linspace(0, fs/2, len(noise_level)),\n",
    "                                    noise_level)\n",
    "            noise_floor = np.percentile(psd_noisy, 10) * noise_weights\n",
    "        else:\n",
    "            noise_floor = np.percentile(psd_noisy, 10)\n",
    "        \n",
    "        # 3. Frequency-band specific SNR calculation\n",
    "        bands = {\n",
    "            'cardiac': (0.8, 4),    # Typical heart rate range\n",
    "            'respiration': (0.1, 0.5),\n",
    "            'motion': (0.5, 10)\n",
    "        }\n",
    "        \n",
    "        snr_values = []\n",
    "        for band_name, (low, high) in bands.items():\n",
    "            band_mask = (freqs >= low) & (freqs <= high)\n",
    "            signal_power = np.trapz(psd_clean[band_mask], freqs[band_mask])\n",
    "            noise_power = np.trapz(noise_floor[band_mask], freqs[band_mask])\n",
    "            \n",
    "            # Add epsilon to avoid division by zero\n",
    "            snr = 10 * np.log10((signal_power + 1e-9) / (noise_power + 1e-9))\n",
    "            snr_values.append(snr)\n",
    "        \n",
    "        # 4. Weighted composite SNR (emphasize cardiac band)\n",
    "        weights = np.array([0.6, 0.2, 0.2])  # Cardiac, Respiration, Motion\n",
    "        return np.dot(snr_values, weights)\n",
    "\n",
    "    def compute_artifact_density(self, motion_burst: np.ndarray,\n",
    "                                noise_level: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Compute noise-weighted artifact density.\n",
    "        \n",
    "        Parameters:\n",
    "            motion_burst (np.ndarray): Binary motion artifact indicators\n",
    "            noise_level (np.ndarray): Associated noise levels\n",
    "            \n",
    "        Returns:\n",
    "            float: Weighted artifact density percentage\n",
    "        \"\"\"\n",
    "        # Weight artifacts by their noise level contribution\n",
    "        weighted_artifacts = motion_burst * noise_level\n",
    "        return 100 * np.sum(weighted_artifacts) / np.sum(noise_level)\n",
    "\n",
    "    def temporal_consistency(self, signal: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Measure signal continuity using autocorrelation.\n",
    "        \n",
    "        Parameters:\n",
    "            signal (np.ndarray): Processed signal\n",
    "            \n",
    "        Returns:\n",
    "            float: Consistency metric (higher = more consistent)\n",
    "        \"\"\"\n",
    "        autocorr = np.correlate(signal, signal, mode='full')\n",
    "        autocorr /= autocorr.max()\n",
    "        mid = len(autocorr) // 2\n",
    "        return np.trapz(autocorr[mid:mid+300])  # Integrate first 10s correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 2.23 dB, Artifact Density: 2.37%\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics using original BVP as reference\n",
    "metrics = SignalQualityMetrics()\n",
    "snr = metrics.compute_snr(processed_df['bvp_cleaned'], \n",
    "                         processed_df['bvp'],\n",
    "                         processed_df['noise_level'])\n",
    "\n",
    "artifact_density = metrics.compute_artifact_density(processed_df['motion_burst'].values, processed_df['noise_level'].values)\n",
    "\n",
    "print(f\"SNR: {snr:.2f} dB, Artifact Density: {artifact_density:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to ../data/cleaned_signal_dataset\n"
     ]
    }
   ],
   "source": [
    "pipeline.save_cleaned_dataset(dataset, \"../data/cleaned_signal_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stress_monitor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
